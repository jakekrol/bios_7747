digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140502993686672 [label="
 (100, 7)" fillcolor=darkolivegreen1]
	140502993487904 [label=AddmmBackward0]
	140502993488336 -> 140502993487904
	140502583109568 [label="fc.4.bias
 (7)" fillcolor=lightblue]
	140502583109568 -> 140502993488336
	140502993488336 [label=AccumulateGrad]
	140502993488240 -> 140502993487904
	140502993488240 [label=ReluBackward0]
	140502993488144 -> 140502993488240
	140502993488144 [label=AddmmBackward0]
	140502993488480 -> 140502993488144
	140502583110048 [label="fc.1.bias
 (100)" fillcolor=lightblue]
	140502583110048 -> 140502993488480
	140502993488480 [label=AccumulateGrad]
	140502993488432 -> 140502993488144
	140502993488432 [label=ViewBackward0]
	140502993488576 -> 140502993488432
	140502993488576 [label=MaxPool2DWithIndicesBackward0]
	140502993488864 -> 140502993488576
	140502993488864 [label=CudnnBatchNormBackward0]
	140502993488960 -> 140502993488864
	140502993488960 [label=ReluBackward0]
	140502993489104 -> 140502993488960
	140502993489104 [label=ConvolutionBackward0]
	140502993489200 -> 140502993489104
	140502993489200 [label=CudnnBatchNormBackward0]
	140502993489392 -> 140502993489200
	140502993489392 [label=ReluBackward0]
	140502993489584 -> 140502993489392
	140502993489584 [label=ConvolutionBackward0]
	140502993489680 -> 140502993489584
	140502583072864 [label="conv.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	140502583072864 -> 140502993489680
	140502993489680 [label=AccumulateGrad]
	140502993489632 -> 140502993489584
	140502583072704 [label="conv.0.bias
 (32)" fillcolor=lightblue]
	140502583072704 -> 140502993489632
	140502993489632 [label=AccumulateGrad]
	140502993489344 -> 140502993489200
	140502583072544 [label="conv.2.weight
 (32)" fillcolor=lightblue]
	140502583072544 -> 140502993489344
	140502993489344 [label=AccumulateGrad]
	140502993489296 -> 140502993489200
	140502583072224 [label="conv.2.bias
 (32)" fillcolor=lightblue]
	140502583072224 -> 140502993489296
	140502993489296 [label=AccumulateGrad]
	140502993489152 -> 140502993489104
	140502583071184 [label="conv.4.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140502583071184 -> 140502993489152
	140502993489152 [label=AccumulateGrad]
	140502993488048 -> 140502993489104
	140502583070944 [label="conv.4.bias
 (64)" fillcolor=lightblue]
	140502583070944 -> 140502993488048
	140502993488048 [label=AccumulateGrad]
	140502993488912 -> 140502993488864
	140502583073424 [label="conv.6.weight
 (64)" fillcolor=lightblue]
	140502583073424 -> 140502993488912
	140502993488912 [label=AccumulateGrad]
	140502993488672 -> 140502993488864
	140502583132384 [label="conv.6.bias
 (64)" fillcolor=lightblue]
	140502583132384 -> 140502993488672
	140502993488672 [label=AccumulateGrad]
	140502993488000 -> 140502993488144
	140502993488000 [label=TBackward0]
	140502993488192 -> 140502993488000
	140502583110368 [label="fc.1.weight
 (100, 4096)" fillcolor=lightblue]
	140502583110368 -> 140502993488192
	140502993488192 [label=AccumulateGrad]
	140502993488288 -> 140502993487904
	140502993488288 [label=TBackward0]
	140502993488720 -> 140502993488288
	140502583109808 [label="fc.4.weight
 (7, 100)" fillcolor=lightblue]
	140502583109808 -> 140502993488720
	140502993488720 [label=AccumulateGrad]
	140502993487904 -> 140502993686672
}
